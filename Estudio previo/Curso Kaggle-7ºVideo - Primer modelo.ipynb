{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Deep Learning Home Page](https://www.kaggle.com/learn/deep-learning)**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los modelos de aprendizaje profundo que hemos construido hasta ahora han utilizado la transferencia de treanferendia de aprendizajes.\n",
    "El aprendizaje que termite construir modelo precisos e incluso con relativamente pocos datos, pero el aprendizaje de transferencia no es necesario en datos grandes, establece y solo funciona cuando su caso de uso tiene patrones visuales similares a los datos utilizamos en el modelo pre entrenado, por ejemplo un modelo pre entrenado basado en las fotos cotidianas no funcionara bien para aplicaciones de fotogracias satelite o para imagenes medicas de una maquina de rosonancia magnetica, asiq si quieres ser versatil con profuncidad aprenderas que tendras que aprender a construir modelos.\n",
    "\n",
    "El codigo para esto es casi identico al que ya hemos utilizado con el aprendizaje de transferencia, vamos a verlo en un ejemplo basado en el ejemplo de mmiss.\n",
    "\n",
    "Almacenar todas las imagenes en una sola:\n",
    "- **train_file = \"directorio\"**\n",
    "- **raw_data = pd.read_csv(train_file)**\n",
    "Cada imagen se representa por una fila del CSV, la primera columna tiene la etiqueta en la que dice que digito se muestra en cada fila, el resto de columna representa pixelesm la intensidad de los pixeles se representan en el csv como una fila de 784 pixeles en 10. \n",
    "\n",
    "Función de preparación de datos para extraer las etiquetas y remodelar la intensidad de pixeles:\n",
    "- **img_rows, img_cols = 28, 28**\n",
    "- **num_classes=10**\n",
    "- **def data_prep(raw):**\n",
    "    - **out_y= keras.utils.to_categorical(raw.label, num_classes)** funcion categorica sumministramos la etiqueta de fila variable oj¡bjetivo, asi como el numero de valores diferentes a categoricos devuelve uno codificado en caliente version del objetivo por lo que representa el 10,valores del objetivo con 10 columnas binarias separadas \n",
    "    - **x_as_array=raw.shape[0]**\n",
    "    - **x_as_array= raw.values[:,1:]** ahora trabajaremos en las intensidades de pixeles los valores de punto sin procesar nos da el dato como una matriz numpy usamos indexación para timar todo despues d ela primera columna, porq la primera columna era la etiqueta, cambiaremos esta dorma a una matriz 4d que \n",
    "    - **x_shaped_array=x_as_array.reshape(num_images, img_rows, img_cols, 1)** esta indexado por el numero de imagen, el numero de fila, el numero de columna y canaliza las imageens en escala de grises en lugar de color, por lo que finalmente solo hay un canal\n",
    "   - **out_x=x_shaped_array / 255** divide los valores entre 255 para que todos los datos esten entre 0 y 1, esto mejora la optimizacion con los parametros predeterminados para el optimizados de atomos \n",
    "    - **return out_x, out_y**\n",
    "   \n",
    " Esta función nos dio una serie de predictores que llamaremos X y una matriz del objetivo que llamare Y \n",
    "**x, y = data_prep(raw_data)**\n",
    "\n",
    "Ahora construimos nuestro modelo:\n",
    "- **model = sequential()**\n",
    "- **model.add(Conv2D(20, kernel_size=(3,3), activation = relu', input_shape=(img_row, img_cols), 1))**\n",
    "- **model.add(Conv2D(20, kernel_size=(3,3), activation = relu'))**\n",
    "Agregamos una capa de convolución 2D a otra capa de convolución 2D, especeficamos alguno argumento necesario como el numero circunvoluciones (2D) o filtros que se incluiran en esa capa, el tamaño y los pixeles de convoluciones que se llama el tamaño del nucleo (kerne_size=(3,3)) y la funcion de activacion para la primera capa (activation = 'relu'), tambien necesito especificar la forma de cada imagen pero no la necesitare especificar en las capa posteriores (input_shape= img_row, img_cols)\n",
    "Hemos utilizado dos capas convolucionales, pero podria haber usamos mas si hubiera querido\n",
    "- **model.add(Flatten())** \n",
    "con el aprendizaje por transferencia, usare una capa aplanada en algun momento para convertir la salida de las capas anteriores en una representacion 1d para cada imagen, \n",
    "- **model.add(Dense(128, activation = 'softmax')**\n",
    "estos modelo generalmente funcionan mejor si agrega una caoa densa entre los planos y una capa de prediccion final, asi que agregare una capa densa con 128 nodos \n",
    "- **model.add(Dense(num_classes, activation = 'softmax'))**\n",
    "finalmente tendremos una capa de salida que es la misma que las capas de salida que has escrito antes de compilarlo con los mismos argumentos que has visto antes\n",
    "- **model.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=['accuracy'])**\n",
    "- **moedel.fit(x,y,batch_size=128, epochs=2, validacion_split=0.2)**\n",
    "ajustamos porque tengo toda una informacion cargada, ya use el comando de ajuste en lugar del comando del generador de ajuste que utilizamos con el generador de datos de imagen que nos proporciono los predictores X y el objetivo Y, especifico un tamalo de lote y varia epocas y finalmente quiero obtener una puntuacion de validacion, asiq utiliza el argumento de division de validacion para decir que el 20% de los datos debe reservarse para la validacion dejando el 80% para la capacitacion.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "You've seen how to build a model from scratch to identify handwritten digits.  You'll now build a model to identify different types of clothing.  To make models that train quickly, we'll work with very small (low-resolution) images. \n",
    "As an example, your model will take an images like this and identify it as a shoe:\n",
    "\n",
    "Has visto cómo construir un modelo desde cero para identificar dígitos escritos a mano. Ahora construirá un modelo para identificar diferentes tipos de ropa. Para hacer modelos que entrenan rápidamente, trabajaremos con imágenes muy pequeñas (de baja resolución).\n",
    "\n",
    "Como ejemplo, su modelo tomará imágenes como esta y lo identificará como un zapato:\n",
    "\n",
    "![Imgur](https://i.imgur.com/GyXOnSB.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "This code is supplied, and you don't need to change it. Just run the cell below.\n",
    "\n",
    "Este código se proporciona y no necesita cambiarlo. Solo ejecuta la celda de abajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "num_classes = 10\n",
    "\n",
    "def prep_data(raw):\n",
    "    y = raw[:, 0]\n",
    "    out_y = keras.utils.to_categorical(y, num_classes)\n",
    "    \n",
    "    x = raw[:,1:]\n",
    "    num_images = raw.shape[0]\n",
    "    out_x = x.reshape(num_images, img_rows, img_cols, 1)\n",
    "    out_x = out_x / 255\n",
    "    return out_x, out_y\n",
    "\n",
    "fashion_file = \"../input/fashionmnist/fashion-mnist_train.csv\"\n",
    "fashion_data = np.loadtxt(fashion_file, skiprows=1, delimiter=',')\n",
    "x, y = prep_data(fashion_data)\n",
    "\n",
    "# Set up code checking\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.deep_learning.exercise_7 import *\n",
    "print(\"Setup Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Start the model\n",
    "Create a `Sequential` model called `fashion_model`. Don't add layers yet.\n",
    "\n",
    "Cree un modelo secuencial llamado fashion_model. No agregue capas todavía."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "fashion_model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "\n",
    "# Your Code Here\n",
    "fashion_model=Sequential()\n",
    "# Check your answer\n",
    "q_1.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#q_1.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Add the first layer\n",
    "\n",
    "Add the first `Conv2D` layer to `fashion_model`. It should have 12 filters, a kernel_size of 3 and the `relu` activation function. The first layer always requires that you specify the `input_shape`.  We have saved the number of rows and columns to the variables `img_rows` and `img_cols` respectively, so the input shape in this case is `(img_rows, img_cols, 1)`.\n",
    "\n",
    "Agrega la primera capa\n",
    "\n",
    "Agregue la primera capa Conv2D a fashion_model. Debe tener 12 filtros, un kernel_size de 3 y la función de activación relu. La primera capa siempre requiere que especifique input_shape. Hemos guardado el número de filas y columnas en las variables img_rows e img_cols respectivamente, por lo que la forma de entrada en este caso es (img_rows, img_cols, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code her\n",
    "fashion_model.add(Conv2D(12, kernel_size=3, activation='relu',input_shape=(img_rows, img_cols,1)))\n",
    "\n",
    "# Check your answer\n",
    "q_2.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_2.hint()\n",
    "#q_2.solution()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**solucion**\n",
    "img_rows, img_cols = 28, 28\n",
    "fashion_model.add(Conv2D(12, activation='relu', kernel_size=3, input_shape = (img_rows, img_cols, 1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Add the remaining layers\n",
    "\n",
    "1. Add 2 more convolutional (`Conv2D layers`) with 20 filters each, 'relu' activation, and a kernel size of 3. Follow that with a `Flatten` layer, and then a `Dense` layer with 100 neurons. \n",
    "2. Add your prediction layer to `fashion_model`.  This is a `Dense` layer.  We alrady have a variable called `num_classes`.  Use this variable when specifying the number of nodes in this layer. The activation should be `softmax` (or you will have problems later).\n",
    "\n",
    "Agrega las capas restantes\n",
    "\n",
    "1. Agregue 2 más convolucionales (capas Conv2D) con 20 filtros cada uno, activación 'relu' y un tamaño de núcleo de 3. Siga eso con una capa Flatten, y luego una capa Densa con 100 neuronas.\n",
    "2. Agregue su capa de predicción a fashion_model. Esta es una capa densa. Ya tenemos una variable llamada num_classes. Use esta variable cuando especifique el número de nodos en esta capa. La activación debe ser softmax (o tendrá problemas más adelante).\n",
    "\n",
    "\n",
    "**fashion_model.add(Conv2D(20, activation='relu', kernel_size=3))**\n",
    "\n",
    "**fashion_model.add(Conv2D(20, activation='relu', kernel_size=3))**\n",
    "\n",
    "**fashion_model.add(Flatten())**\n",
    "\n",
    "**fashion_model.add(Dense(100, activation='relu'))**\n",
    "\n",
    "**fashion_model.add(Dense(10, activation='softmax'))**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "fashion_model.add(Conv2D(20, activation='relu', kernel_size=3))\n",
    "fashion_model.add(Conv2D(20, activation='relu', kernel_size=3))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_model.add(Dense(100, activation='relu'))\n",
    "fashion_model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your answer\n",
    "q_3.check()\n",
    "q_3.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Compile Your Model\n",
    "Compile fashion_model with the `compile` method.  Specify the following arguments:\n",
    "1. `loss = \"categorical_crossentropy\"`\n",
    "2. `optimizer = 'adam'`\n",
    "3. `metrics = ['accuracy']`\n",
    "\n",
    "Compila tu modelo\n",
    "Compile fashion_model con el método de compilación. Especifique los siguientes argumentos:\n",
    "- `loss = \"categorical_crossentropy\"`\n",
    "-  `optimizer = 'adam'`\n",
    "-  `metrics = ['accuracy']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code to compile the model in this cell\n",
    "\n",
    "fashion_model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "# Check your answer\n",
    "q_4.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_4.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Fit The Model\n",
    "Run the command `fashion_model.fit`. The arguments you will use are\n",
    "1. The data used to fit the model. First comes the data holding the images, and second is the data with the class labels to be predicted. Look at the first code cell (which was supplied to you) where we called `prep_data` to find the variable names for these.\n",
    "2. `batch_size = 100`\n",
    "3. `epochs = 4`\n",
    "4. `validation_split = 0.2`\n",
    "\n",
    "When you run this command, you can watch your model start improving.  You will see validation accuracies after each epoch.\n",
    "\n",
    "Ajustar el modelo\n",
    "Ejecute el comando fashion_model.fit. Los argumentos que usarás son\n",
    "\n",
    "1. Los datos utilizados para ajustarse al modelo. Primero vienen los datos que contienen las imágenes, y segundo están los datos con las etiquetas de clase a predecir. Mire la primera celda de código (que se le proporcionó) donde llamamos a prep_data para encontrar los nombres de las variables para estos.\n",
    "2. batch_size = 100\n",
    "3. épocas = 4\n",
    "4. validation_split = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code to fit the model here\n",
    "\n",
    "fashion_model.fit(x,y, batch_size=100, epochs=4, validation_split=0.2)\n",
    "\n",
    "# Check your answer\n",
    "q_5.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#q_5.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Create A New Model\n",
    "\n",
    "Create a new model called `second_fashion_model` in the cell below.  Make some changes so it is different than `fashion_model` that you've trained above. The change could be using a different number of layers, different number of convolutions in the layers, etc.\n",
    "\n",
    "Define the model, compile it and fit it in the cell below.  See how its validation score compares to that of the original model.\n",
    "\n",
    "Crear un nuevo modelo\n",
    "\n",
    "Cree un nuevo modelo llamado second_fashion_model en la celda a continuación. Realice algunos cambios para que sea diferente de fashion_model que ha entrenado anteriormente. El cambio podría estar usando un número diferente de capas, un número diferente de convoluciones en las capas, etc.\n",
    "\n",
    "Defina el modelo, compílelo y ajústelo en la celda de abajo. Vea cómo su puntaje de validación se compara con el del modelo original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_fashion_model = Sequential()\n",
    "second_fashion_model.add(Conv2D(12,\n",
    "                         activation='relu',\n",
    "                         kernel_size=3,\n",
    "                         input_shape = (img_rows, img_cols, 1)))\n",
    "# Changed kernel sizes to be 2\n",
    "second_fashion_model.add(Conv2D(20, activation='relu', kernel_size=2))\n",
    "second_fashion_model.add(Conv2D(20, activation='relu', kernel_size=2))\n",
    "# added an addition Conv2D layer\n",
    "second_fashion_model.add(Conv2D(20, activation='relu', kernel_size=2))\n",
    "second_fashion_model.add(Flatten())\n",
    "second_fashion_model.add(Dense(100, activation='relu'))\n",
    "# It is important not to change the last layer. First argument matches number of classes. Softmax guarantees we get reasonable probabilities\n",
    "second_fashion_model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "second_fashion_model.compile(loss='categorical_crossentropy',\n",
    "                             optimizer='adam',\n",
    "                             metrics=['accuracy'])\n",
    "\n",
    "second_fashion_model.fit(x, y, batch_size=100, epochs=4, validation_split=0.2)\n",
    "\n",
    "q_6.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#q_6.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keep Going\n",
    "You are ready to learn about **[strides and dropout](https://www.kaggle.com/dansbecker/dropout-and-strides-for-larger-models)**, which become important as you start using bigger and more powerful models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**[Deep Learning Home Page](https://www.kaggle.com/learn/deep-learning)**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*Have questions or comments? Visit the [Learn Discussion forum](https://www.kaggle.com/learn-forum) to chat with other Learners.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
