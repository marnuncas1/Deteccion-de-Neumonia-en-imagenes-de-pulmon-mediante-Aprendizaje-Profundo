{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Deep Learning Home Page](https://www.kaggle.com/learn/deep-learning)**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APUNTES\n",
    "4º Video curso deep Learning\n",
    "\n",
    "Secuencial nos dice que nuestro modelo va a ser una secuencia de capas unas tras otras\n",
    "**my_new_model = sequential()**\n",
    "\n",
    "**my_new_model.add(ResNet50(include_top=False, weigths=weights_path, pooling=’avg’))**\n",
    "\n",
    "- **include_top=False** > excluimos las capas que hace predicciones en las miles de categorías utilizadas en la competencia de imagenet\n",
    "\n",
    "- **weigths=weights_path** > usaremos un archivo que no incluya los pesos\n",
    "\n",
    "- **pooling=’avg’** > para la ultima capa entregamos este agrupamiento de argumentos igual al promedio que dice que  si tuvieramos canales adicionales en nuestro tensor al final de este paso desea contraerlos en un tensor 1d tomando un promedio a traves de los canales\n",
    "\n",
    "avg significa que el promedio global se aplicará a la salida del último bloque convolucional, y por lo tanto la salida del modelo será un tensor 2D.\n",
    "**num_classes = 2** \n",
    "\n",
    "**my_new_model.add(Dense(num_classes, actuvation= ‘sotfmax'))**\n",
    "\n",
    "    - Agregue capas densas para hacer predicciones especificando el número de nodos en esta capa que en este caso es el número de clases \n",
    "\n",
    "    - Después decimos que queremos aplicar la función softmax para convertirla en probabilidades\n",
    "    \n",
    "**my_new_model.layers[0].trainable =False**\n",
    "\n",
    "No entrenar la primera capa ya que es el modelo ResNet50 ya que es el modelo entrenado previamente con imagenet\n",
    "\n",
    "**my_new_model.compile(optimizer=’sdg’, loss= ‘categorical_crossentropy’, metrics=[‘accuracy’]’)**\n",
    "\n",
    "Dice como actualizar las relaciones en la conexiones densas. Cuando estamos entrenando con nuestros datos tenemos una medida de pérdida o imprecisión que queremos minimizar especificamos como entropía cruzada categórica\n",
    "Se usa mediante el algoritmo descenso de gradiente estocástico para minimizar la función de pérdida de entropía cruzada categórica \n",
    "\n",
    "Hay dos pasos para usar el generador de datos de imagen:\n",
    "\n",
    "- 1º crearemos cualquier objeto generador en abstracto. Le dire que queremos aplicar la función de preprocesamiento ResNet cada vez que le una imagen que va a usar , esta función es coherente con la forma en que se crea el modelo resident from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "**data_generator = ImagenDataGenerator(preprocessing_function=preprocess_input)**\n",
    "\n",
    "- Usamos el comando de flujo desde el directorio y le decimos que directorio \n",
    "**train_generator=data_generator.flow_from_directory(‘directoriodondeestanlosdatos’, target_size(image_size, image_size), batch_size=12, class_mode=’categorical’)**\n",
    "\n",
    "    - target_size(image_size, image_size) > el tamaña en el que estan los datos\n",
    "    - batch_size=12 > cuantas imagenes queremos leer a la vez\n",
    "    - class_mode=’categorical’ > clasificar las imagenes en diferentes categorias\n",
    "\n",
    "Datos de validación: \n",
    "\n",
    "**validation_generator=data_generator.flow_from_directory(‘directoriodondeestanlosdatos’, target_size(image_size, image_size), batch_size=12, class_mode=’categorical’)**\n",
    "\n",
    "**my_new_model.fit_generator(train_generator, steps_per_epoch=6, validation_data=validation_generator, validation_steps=1)**\n",
    "\n",
    "    - steps_per_epoch=6 > 6 pasos de 12 imagenes\n",
    "    - validation_data=validation_generator > los datos de validacion proceden de validation_generator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Introduction\n",
    "\n",
    "The cameraman who shot our deep learning videos mentioned a problem that we can solve with deep learning.  \n",
    "He offers a service that scans photographs to store them digitally.  He uses a machine that quickly scans many photos. But depending on the orientation of the original photo, many images are digitized sideways.  He fixes these manually, looking at each photo to determine which ones to rotate.\n",
    "In this exercise, you will build a model that distinguishes which photos are sideways and which are upright, so an app could automatically rotate each image if necessary.\n",
    "If you were going to sell this service commercially, you might use a large dataset to train the model. But you'll have great success with even a small dataset.  You'll work with a small dataset of dog pictures, half of which are rotated sideways.\n",
    "Specifying and compiling the model look the same as in the example you've seen. But you'll need to make some changes to fit the model.\n",
    "**Run the following cell to set up automatic feedback.**\n",
    "\n",
    "\n",
    "El camarógrafo que filmó nuestros videos de aprendizaje profundo mencionó un problema que podemos resolver con el aprendizaje profundo.\n",
    "\n",
    "Ofrece un servicio que escanea fotografías para almacenarlas digitalmente. Él usa una máquina que escanea rápidamente muchas fotos. Pero dependiendo de la orientación de la foto original, muchas imágenes se digitalizan de lado. Los arregla manualmente, mirando cada foto para determinar cuáles rotar.\n",
    "\n",
    "En este ejercicio, creará un modelo que distingue qué fotos están de lado y cuáles están en posición vertical, de modo que una aplicación podría rotar automáticamente cada imagen si es necesario.\n",
    "\n",
    "Si iba a vender este servicio comercialmente, podría usar un gran conjunto de datos para entrenar el modelo. Pero tendrá un gran éxito incluso con un pequeño conjunto de datos. Trabajará con un pequeño conjunto de datos de imágenes de perros, la mitad de los cuales se giran hacia los lados.\n",
    "\n",
    "Especificar y compilar el modelo tiene el mismo aspecto que en el ejemplo que ha visto. Pero deberá realizar algunos cambios para adaptarse al modelo.\n",
    "\n",
    "Ejecute la siguiente celda para configurar la retroalimentación automática."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up code checking\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.deep_learning.exercise_4 import *\n",
    "print(\"Setup Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Specify the Model\n",
    "\n",
    "Since this is your first time, we'll provide some starter code for you to modify. You will probably copy and modify code the first few times you work on your own projects.\n",
    "There are some important parts left blank in the following code.\n",
    "Fill in the blanks (marked with `____`) and run the cell\n",
    "\n",
    "Especifica el modelo\n",
    "\n",
    "Como es la primera vez, le proporcionaremos un código de inicio para que lo modifique. Probablemente copiará y modificará el código las primeras veces que trabaje en sus propios proyectos.\n",
    "\n",
    "Hay algunas partes importantes que se dejan en blanco en el siguiente código.\n",
    "\n",
    "Complete los espacios en blanco (marcados con ____) y ejecute la celda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "\n",
    "#numero de nodos que va a tener \n",
    "num_classes = 2\n",
    "resnet_weights_path = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "#modelo secuencial\n",
    "my_new_model = Sequential()\n",
    "#modelo al que podemos agregar capas, primero agregamos un modelo pre-entrenado, poniendo include_top=false \n",
    "#excluimos las capas que hace predicciones en las miles de categorías utilizadas en la competencia de imagenet \n",
    "# weights=resnet_weights_path, archivo que no incluya los pesos\n",
    "my_new_model.add(ResNet50(include_top=False, pooling='avg', weights=resnet_weights_path))\n",
    "#activation='softmax, función de activación\n",
    "#Densidad, relaciona todos los nodos de la capa anterior con la siguiente es decir si tengo \n",
    "# 10 nodos en una y 10 en otra habrá 100 conexiones\n",
    "my_new_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Indicate whether the first layer should be trained/changed or not.\n",
    "#No entrenar la primera capa ya que es el modelo ResNet50 ya que es el modelo entrenado previamente con imagenet\n",
    "\n",
    "my_new_model.layers[0].trainable = False\n",
    "\n",
    "# Check your answer\n",
    "step_1.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_1.hint()\n",
    "step_1.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Compile the Model\n",
    "\n",
    "You now compile the model with the following line.  Run this cell.\n",
    "\n",
    "Compila el modelo\n",
    "Ahora compila el modelo con la siguiente línea. Ejecute esta celda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dice como actualizar las relaciones en la conexiones densas. Cuando estamos entrenando con nuestros datos tenemos una \n",
    "#medida de pérdida o imprecisión que queremos minimizar especificamos como entropía cruzada categórica\n",
    "#Se usa mediante el algoritmo descenso de gradiente estocástico para minimizar la función de pérdida de entropía \n",
    "#cruzada categórica \n",
    "\n",
    "my_new_model.compile(optimizer='sgd', \n",
    "                     loss='categorical_crossentropy', \n",
    "                     metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That ran nearly instantaneously. Deep learning models have a reputation for being computationally demanding. Why did that run so quickly? After thinking about this, check your answer by uncommenting the cell below.\n",
    "\n",
    "Eso corrió casi instantáneamente. Los modelos de aprendizaje profundo tienen la reputación de ser computacionalmente exigentes. ¿Por qué corrió eso tan rápido? Después de pensar en esto, verifique su respuesta descomentando la celda a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your answer (Run this code cell to receive credit!)\n",
    "step_2.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo de compilación no cambia los valores en ninguna convolución. De hecho, su modelo aún no ha recibido una discusión con datos. La compilación especifica cómo su modelo realizará actualizaciones en un paso posterior en el que recibirá datos. Esa es la parte que llevará más tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Review the Compile Step\n",
    "You provided three arguments in the compile step.  \n",
    "- optimizer\n",
    "- loss\n",
    "- metrics\n",
    "\n",
    "Which arguments could affect the accuracy of the predictions that come out of the model?  After you have your answer, run the cell below to see the solution.\n",
    "\n",
    "Revisar el paso de compilación\n",
    "Usted proporcionó tres argumentos en el paso de compilación.\n",
    "\n",
    "- optimizador\n",
    "- pérdida\n",
    "- métrica\n",
    "\n",
    "¿Qué argumentos podrían afectar la precisión de las predicciones que salen del modelo? Después de tener su respuesta, ejecute la celda a continuación para ver la solución.\n",
    "- El optimizador determina cómo determinamos los valores numéricos que componen el modelo. Por lo tanto, puede afectar el modelo resultante y las predicciones.\n",
    "- la pérdida determina qué objetivo optimizamos al determinar los valores numéricos en el modelo. Por lo tanto, puede afectar el modelo resultante y las predicciones.\n",
    "- la métrica determina solo lo que imprimimos mientras se construye el modelo, pero no afecta el modelo en sí.\n",
    "Puede que aún no entiendas todo esto. Eso está totalmente bien por ahora. Será más claro en una próxima lección (llamada Una comprensión más profunda del aprendizaje profundo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your answer (Run this code cell to receive credit!)\n",
    "step_3.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Fit Model\n",
    "\n",
    "**Your training data is in the directory `../input/dogs-gone-sideways/images/train`. The validation data is in `../input/dogs-gone-sideways/images/val`**. Use that information when setting up `train_generator` and `validation_generator`.\n",
    "You have 220 images of training data and 217 of validation data.  For the training generator, we set a batch size of 10. Figure out the appropriate value of `steps_per_epoch` in your `fit_generator` call.\n",
    "Fill in all the blanks (again marked as `____`).  Then run the cell of code.  Watch as your model trains the weights and the accuracy improves.\n",
    "\n",
    "\n",
    "Sus datos de entrenamiento están en el directorio ../input/dogs-gone-sideways/images/train. Los datos de validación están en ../input/dogs-gone-sideways/images/val. Use esa información cuando configure train_generator y validation_generator.\n",
    "Tienes 220 imágenes de datos de entrenamiento y 217 de datos de validación. Para el generador de entrenamiento, establecemos un tamaño de lote de 10. Calcule el valor apropiado de steps_per_epoch en su llamada fit_generator.\n",
    "Complete todos los espacios en blanco (nuevamente marcado como ____). Luego ejecute la celda de código. Observe cómo su modelo entrena los pesos y la precisión mejora.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "image_size = 224\n",
    "data_generator = ImageDataGenerator(preprocess_input)\n",
    "\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "    #DIRECTORIO SOBRE LO QUE TRABAJAMOS Y SOBRE LOS QUE SE REALIZARÁ EL GENERADOR DE LOTES\n",
    "                                        directory=./dogs-gone-sideways/images/train,\n",
    "    #DIMENSION\n",
    "                                        target_size=(image_size, image_size),\n",
    "    #TAMAÑO DEL LOTE DE IMAGENES\n",
    "                                        batch_size=10,\n",
    "    #TIPO DE ETIQUETAS\n",
    "                                        class_mode='categorical')\n",
    "\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "        #DIRECTORIO SOBRE LO QUE TRABAJAMOS Y SOBRE LOS QUE SE REALIZARÁ EL GENERADOR DE LOTES\n",
    "                                        directory=\"./dogs-gone-sideways/images/val\",\n",
    "                                        target_size=(image_size, image_size),\n",
    "                                        class_mode='categorical')\n",
    "\n",
    "# fit_stats below saves some statistics describing how model fitting went\n",
    "# the key role of the following line is how it changes my_new_model by fitting to data\n",
    "fit_stats = my_new_model.fit_generator(train_generator,\n",
    "                                       steps_per_epoch=22,\n",
    "                                       validation_data=validation_generator,\n",
    "                                       validation_steps=1)\n",
    "\n",
    "# Check your answer\n",
    "step_4.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_4.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Can you tell from the results what fraction of the time your model was correct in the validation data? \n",
    "\n",
    "In the next step, we'll see if we can improve on that.\n",
    "\n",
    "# Keep Going\n",
    "Move on to learn about **[data augmentation](https://www.kaggle.com/dansbecker/data-augmentation/)**.  It is a clever and easy way to improve your models. Then you'll apply data augmentation to this automatic image rotation problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**[Deep Learning Home Page](https://www.kaggle.com/learn/deep-learning)**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*Have questions or comments? Visit the [Learn Discussion forum](https://www.kaggle.com/learn-forum) to chat with other Learners.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
